# Custom-Chatbot-with-Quantized-Llama3-8b
## Unsloth
Unsloth is an framework for fine-tuning large language models like Llama 3 due to its efficient memory management and simplified process.
It supports 4-bit quantization, which reduces memory usage, computational requirements and speeds up computations.
## Parameter-Efficient Fine-Tuning (PEFT) and Low-Rank Adaptation (LoRA)
Unsloth supports Parameter-Efficient Fine-Tuning (PEFT) techniques, which focus on adjusting only a small subset of a model's parameters during the fine-tuning process, significantly reducing computational and memory requirements.
One such technique within PEFT is LoRA (Low-Rank Adaptation), which allows models to learn task-specific features with significantly fewer parameters. By using LoRA, the training process is sped up while maintaining high performance on specific tasks.

